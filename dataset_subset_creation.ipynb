{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset_subset_creation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorenoSara/Summarizing-Long-Form-Document-with-Rich-Discourse-Information/blob/main/dataset_subset_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook shows how we extracted the training/validation/test data subsets for our model and how we merged arXiv and PubMed for the extension"
      ],
      "metadata": {
        "id": "QAKgTmAYvczK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_num_docs = 600\n",
        "val_num_docs = 200\n",
        "test_num_docs = 200"
      ],
      "metadata": {
        "id": "7WnYaeIcWjiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create data subsets"
      ],
      "metadata": {
        "id": "4W0tugjuVBsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def create_subset_file(path, num_docs, subset_data_path):\n",
        "  data = []\n",
        "  i = 0\n",
        "  for line in open(path, 'r'):\n",
        "    i += 1\n",
        "    data.append(json.loads(line))\n",
        "    if i == num_docs:\n",
        "      break\n",
        "  with open(subset_data_path, 'w') as fp:\n",
        "    fp.write(\n",
        "        '' +\n",
        "        '\\n'.join(json.dumps(i) for i in data) +\n",
        "        '\\n')"
      ],
      "metadata": {
        "id": "67wJ9NS8rmRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datapath = '/content/drive/MyDrive/pubmed-dataset/train.txt'\n",
        "train_subset_path = \"/content/drive/MyDrive/pubmed-dataset/train_subset.txt\"\n",
        "create_subset_file(train_datapath, train_num_docs, train_subset_path)"
      ],
      "metadata": {
        "id": "OYVQq-ySsL8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_datapath = '/content/drive/MyDrive/pubmed-dataset/val.txt'\n",
        "val_subset_path = \"/content/drive/MyDrive/pubmed-dataset/val_subset.txt\"\n",
        "create_subset_file(val_datapath, val_num_docs, val_subset_path)"
      ],
      "metadata": {
        "id": "oI-zqTcTtSca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datapath = '/content/drive/MyDrive/pubmed-dataset/test.txt'\n",
        "test_subset_path = \"/content/drive/MyDrive/pubmed-dataset/test_subset.txt\"\n",
        "create_subset_file(test_datapath, test_num_docs, test_subset_path)"
      ],
      "metadata": {
        "id": "1uBx_Mu9tS-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge arxiv and pubmed data subsets in order to perform the extention"
      ],
      "metadata": {
        "id": "1phu1CS0VMan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def combine_arxiv_pubmed_subests(pubmed_sub, arxiv_sub, num_docs, save_path):\n",
        "  data = []\n",
        "  i = 0\n",
        "  for line in open(pubmed_sub, 'r'):\n",
        "    i += 1\n",
        "    data.append(json.loads(line))\n",
        "    if i == num_docs/2:\n",
        "      break\n",
        "  i = 0\n",
        "  for line in open(arxiv_sub, 'r'):\n",
        "    i += 1\n",
        "    data.append(json.loads(line))\n",
        "    if i == num_docs/2:\n",
        "      break\n",
        "  random.shuffle(data)\n",
        "  with open(save_path, 'w') as fp:\n",
        "    fp.write(\n",
        "        '' +\n",
        "        '\\n'.join(json.dumps(i) for i in data) +\n",
        "        '\\n')"
      ],
      "metadata": {
        "id": "5Ly2tdeqn9Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pubmed_train_sub = '/content/drive/MyDrive/pubmed-dataset/train_subset.txt'\n",
        "arxiv_train_sub = '/content/drive/MyDrive/arxiv-dataset/train_subset.txt'\n",
        "arx_pub_train_sub = '/content/drive/MyDrive/arx_pub-dataset/train_subset.txt'\n",
        "combine_arxiv_pubmed_subests(pubmed_train_sub, arxiv_train_sub, train_num_docs, arx_pub_train_sub)"
      ],
      "metadata": {
        "id": "Ibc519iLP0M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pubmed_val_sub = '/content/drive/MyDrive/pubmed-dataset/val_subset.txt'\n",
        "arxiv_val_sub = '/content/drive/MyDrive/arxiv-dataset/val_subset.txt'\n",
        "arx_pub_val_sub = '/content/drive/MyDrive/arx_pub-dataset/val_subset.txt'\n",
        "combine_arxiv_pubmed_subests(pubmed_val_sub, arxiv_val_sub, val_num_docs, arx_pub_val_sub)"
      ],
      "metadata": {
        "id": "VwmE3BbjTSRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pubmed_test_sub = '/content/drive/MyDrive/pubmed-dataset/test_subset.txt'\n",
        "arxiv_test_sub = '/content/drive/MyDrive/arxiv-dataset/test_subset.txt'\n",
        "arx_pub_test_sub = '/content/drive/MyDrive/arx_pub-dataset/test_subset.txt'\n",
        "combine_arxiv_pubmed_subests(pubmed_test_sub, arxiv_test_sub, test_num_docs, arx_pub_test_sub)"
      ],
      "metadata": {
        "id": "72k1hVQXTS-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}